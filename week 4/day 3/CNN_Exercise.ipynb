{"cells":[{"cell_type":"markdown","id":"6edf0915","metadata":{"id":"6edf0915"},"source":["# Convolutional Neural Network (CNN) using Keras\n","This notebook will guide you through the process of creating a CNN model using Keras. Follow the steps and fill in the code blocks as you progress."]},{"cell_type":"markdown","id":"cf19bf02","metadata":{"id":"cf19bf02"},"source":["# Dataset Card: Men vs. Women Classification\n","\n","## Overview\n","The Men vs. Women Classification dataset contains images of men and women intended for binary image classification tasks. The goal is to classify images based on gender.\n","\n","- **Dataset URL:** [Men vs. Women Classification Dataset](https://www.kaggle.com/datasets/saadpd/menwomen-classification)\n","- **Dataset Size:** ~845 MB\n","- **Classes:** 2 (Men, Women)\n","- **Image Format:** JPEG\n","\n","## Structure\n","\n","### Folders\n","The dataset is organized into two main folders:\n","\n","- `traindata/`:\n","  - `traindata/`: Contains the training images.\n","    - `men/`: Contains images of men.\n","    - `women/`: Contains images of women.\n","\n","- `testdata/`:\n","  - `testdata/`: Contains the testing images.\n","    - `men/`: Contains images of men.\n","    - `women/`: Contains images of women.\n","\n","### Example Files\n","Here are some example file names you might find in the dataset:\n","\n","- `traindata/traindata/men/000000899.jpg`\n","- `traindata/traindata/women/00000001.jpg`\n","- `testdata/testdata/men/00000504.jpg`\n","- `testdata/testdata/women/00000002.jpg`\n","\n","### Image Specifications\n","- **Resolution:** Varies\n","- **Color:** RGB\n","\n","## Usage\n","This dataset is ideal for practicing binary image classification using Convolutional Neural Networks (CNNs). It can be used to train a model to distinguish between images of men and women."]},{"cell_type":"markdown","id":"c25150e3","metadata":{"id":"c25150e3"},"source":["## Step 1: Import Required Libraries\n","Begin by importing the necessary libraries."]},{"cell_type":"code","execution_count":null,"id":"aaa74530","metadata":{"id":"aaa74530"},"outputs":[],"source":["# Import libraries\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["!kaggle datasets download -d saadpd/menwomen-classification"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMCVMNorrSCh","executionInfo":{"status":"ok","timestamp":1723551573269,"user_tz":-180,"elapsed":41064,"user":{"displayName":"Saad AlKathiri","userId":"10145741336736662477"}},"outputId":"1d9f9368-3d86-4e9d-8e0d-77c692062cf2"},"id":"AMCVMNorrSCh","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset URL: https://www.kaggle.com/datasets/saadpd/menwomen-classification\n","License(s): copyright-authors\n","Downloading menwomen-classification.zip to /content\n","100% 804M/806M [00:39<00:00, 23.6MB/s]\n","100% 806M/806M [00:39<00:00, 21.5MB/s]\n"]}]},{"cell_type":"markdown","id":"9df0ba8e","metadata":{"id":"9df0ba8e"},"source":["## Step 2: Load and Preprocess Data\n","Load your dataset and preprocess it. This may include resizing images, normalizing pixel values, and splitting the data into training and validation sets."]},{"cell_type":"code","execution_count":15,"id":"561c0bac","metadata":{"id":"561c0bac","executionInfo":{"status":"ok","timestamp":1723551618330,"user_tz":-180,"elapsed":764,"user":{"displayName":"Saad AlKathiri","userId":"10145741336736662477"}},"outputId":"47fe11c2-ca92-4f18-e1f6-8db286b88ca2","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2313 images belonging to 1 classes.\n","Found 266 images belonging to 1 classes.\n"]}],"source":["# Load and preprocess the data\n","# Hint: Use ImageDataGenerator for image preprocessing\n","# Example:\n","\n","img_height = 224\n","img_width = 224\n","batch_size = 32\n","\n","\n","datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","train_generator = datagen.flow_from_directory('/content/traindata', target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical', subset='training')\n","validation_generator = datagen.flow_from_directory('/content/testdata', target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical', subset='validation')"]},{"cell_type":"markdown","id":"2932d543","metadata":{"id":"2932d543"},"source":["## Step 3: Data Augmentation\n","To prevent overfitting, augment your data using various transformations like rotation, zoom, flip, etc."]},{"cell_type":"code","execution_count":16,"id":"b0e284f7","metadata":{"id":"b0e284f7","executionInfo":{"status":"ok","timestamp":1723551621239,"user_tz":-180,"elapsed":8,"user":{"displayName":"Saad AlKathiri","userId":"10145741336736662477"}}},"outputs":[],"source":["# Data Augmentation\n","# Example:\n","# datagen_train = ImageDataGenerator(\n","#    rescale=1./255,\n","#    rotation_range=40,\n","#    width_shift_range=0.2,\n","#    height_shift_range=0.2,\n","#    shear_range=0.2,\n","#    zoom_range=0.2,\n","#    horizontal_flip=True,\n","#    fill_mode='nearest')\n","\n","datagen_train = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest',\n",")"]},{"cell_type":"markdown","id":"d77d214a","metadata":{"id":"d77d214a"},"source":["## Step 4: Build the CNN Model\n","Define the architecture of your CNN model. Start with convolutional layers followed by pooling layers, and end with fully connected layers."]},{"cell_type":"code","execution_count":17,"id":"c4177f7f","metadata":{"id":"c4177f7f","executionInfo":{"status":"ok","timestamp":1723551624087,"user_tz":-180,"elapsed":25,"user":{"displayName":"Saad AlKathiri","userId":"10145741336736662477"}},"outputId":"ee9d2d64-36db-4114-886f-72bb5dbe0c61","colab":{"base_uri":"https://localhost:8080/","height":504}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_3\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │      \u001b[38;5;34m11,075,712\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">11,075,712</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,170,250\u001b[0m (42.61 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,170,250</span> (42.61 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,170,250\u001b[0m (42.61 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,170,250</span> (42.61 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}],"source":["# Build the model\n","# Example:\n","# model = Sequential([\n","#    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n","#    MaxPooling2D(2, 2),\n","#    Conv2D(64, (3, 3), activation='relu'),\n","#    MaxPooling2D(2, 2),\n","#    Flatten(),\n","#    Dense(128, activation='relu'),\n","#    Dropout(0.5),\n","#    Dense(num_classes, activation='softmax')\n","# ])\n","# model.summary()\n","\n","num_classes = 10\n","\n","model = Sequential([\n","    # First convolutional layer\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n","    MaxPooling2D(2, 2),\n","\n","    # Second convolutional layer\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2),\n","\n","    # Third convolutional layer\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    Flatten(),\n","\n","    # Fully connected layer\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","\n","    # Output layer\n","    Dense(num_classes, activation='softmax')\n","])\n","\n","model.summary()"]},{"cell_type":"markdown","id":"066c1d25","metadata":{"id":"066c1d25"},"source":["## Step 5: Compile the Model\n","Compile your model by specifying the optimizer, loss function, and evaluation metrics."]},{"cell_type":"code","execution_count":18,"id":"83b3fe4b","metadata":{"id":"83b3fe4b","executionInfo":{"status":"ok","timestamp":1723551628439,"user_tz":-180,"elapsed":699,"user":{"displayName":"Saad AlKathiri","userId":"10145741336736662477"}}},"outputs":[],"source":["# Compile the model\n","# Example:\n","# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Compile the model\n","model.compile(\n","    optimizer='adam',\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")"]},{"cell_type":"markdown","id":"eec6e31d","metadata":{"id":"eec6e31d"},"source":["## Step 6: Train the Model\n","Train your model using the training data and validate it using the validation data."]},{"cell_type":"code","execution_count":19,"id":"cd761a43","metadata":{"id":"cd761a43","outputId":"8371ac82-eddf-4023-b8b9-f7a38ddcbb19","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723551744757,"user_tz":-180,"elapsed":114042,"user":{"displayName":"Saad AlKathiri","userId":"10145741336736662477"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 434ms/step - accuracy: 0.9380 - loss: 0.1522 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 2/3\n","\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 337ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 3/3\n","\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 341ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"]}],"source":["# Train the model\n","# Example:\n","# history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator)\n","\n","epochs = 3\n","\n","# Train the model\n","history = model.fit(\n","    train_generator,\n","    epochs=epochs,\n","    validation_data=validation_generator\n",")"]},{"cell_type":"markdown","id":"37e265a8","metadata":{"id":"37e265a8"},"source":["## Step 7: Evaluate the Model\n","Evaluate the performance of your model using the validation set."]},{"cell_type":"code","execution_count":20,"id":"08f53419","metadata":{"id":"08f53419","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723551745577,"user_tz":-180,"elapsed":857,"user":{"displayName":"Saad AlKathiri","userId":"10145741336736662477"}},"outputId":"3bced1d4-9ff6-47ca-8e40-d991ef9f7b64"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n","Validation Loss: 0.0\n","Validation Accuracy: 1.0\n"]}],"source":["# Evaluate the model\n","# Example:\n","# loss, accuracy = model.evaluate(validation_generator)\n","# print(f'Validation Loss: {loss}')\n","# print(f'Validation Accuracy: {accuracy}')\n","\n","loss, accuracy = model.evaluate(validation_generator)\n","\n","# Print the results\n","print(f'Validation Loss: {loss}')\n","print(f'Validation Accuracy: {accuracy}')"]},{"cell_type":"markdown","id":"eb612a4c","metadata":{"id":"eb612a4c"},"source":["## Step 8: Save the Model\n","Finally, save your trained model for future use."]},{"cell_type":"code","execution_count":21,"id":"9688067c","metadata":{"id":"9688067c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723551746313,"user_tz":-180,"elapsed":755,"user":{"displayName":"Saad AlKathiri","userId":"10145741336736662477"}},"outputId":"f6ec89c0-2186-4582-9e75-4e1e41f52363"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}],"source":["# Save the model\n","# Example:\n","# model.save('my_cnn_model.h5')\n","\n","# Save the model to a file\n","model.save('my_cnn_model.h5')"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[{"file_id":"1EzxlhvpobyBMNJzig-fj3Xl3ZLds2bjE","timestamp":1723544499416}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}